<h1 align="center" id="打造个人知识库">打造个人知识库</h1>

**概要：** 本章节将介绍如何利用[RAG技术](/AI/02_检索内容增强(RAG))构建个人知识库。



## 为什么要用RAG增强大模型?

因为LLM被局限于自己训练的数据里面了，缺少专业知识、企业内部知识、个人知识。



### 步骤

先将一个或者多个文档进行分段，把这些段落投射为向量空间中的点(向量数据库)。

用户提出问题，问题经过编码，再在向量数据库中做相似性检索，获取与问题相关的信息块*context*，并通过重排序算法，输出最相关的N个*context*。

相关段落*context* + 问题组合形成*prompt*输入大模型中，大模型输出一个答案或采取一个行动

- RAG流程核心：数据入库 + 相关性检索。
- 主要难点在：知识管理（非结构化加载器做文件解析 + 数据如何切片）、知识检索、知识重排序





## 系统组成

一个完整的本地 RAG 系统，通常包括以下模块：

| 模块           | 功能说明                         | 推荐工具/方案（本地可部署）             |
| -------------- | -------------------------------- | --------------------------------------- |
| 1. 文本预处理  | 文档读取、切分、清洗等           | `LangChain`、`llama-index`、`Haystack`  |
| 2. 向量化      | 文本转向量（Embedding）          | `BGE`、`MiniLM`、`text2vec`（开源模型） |
| 3. 向量存储    | 存储向量并支持相似度搜索         | `FAISS`、`Milvus`、`Weaviate`、`Chroma` |
| 4. 检索        | 通过用户输入去相似度搜索匹配内容 | 上述向量库 + 语义搜索                   |
| 5. 大语言模型  | 回答生成                         | `llama3`、`Mistral`、`Yi`、`ChatGLM3`   |
| 6. 对话接口/UI | 提供使用入口（API/网页/聊天框）  | `LangChain` Agent、`Gradio`、`FastAPI`  |



## 本地运行方案

**方案一：LangChain + FAISS + 本地模型（适合轻量本地）**

- **文档处理**：LangChain 内置文档加载器 + 文本分块（RecursiveCharacterTextSplitter）
- **Embedding**：使用开源模型如 `bge-base-zh`（中文）或 `text2vec`，通过 `transformers` 加载
- **向量库**：使用 `FAISS`（轻量、高速，支持内存和磁盘持久化）
- **模型**：本地部署 `llama3-8B-instruct`、`ChatGLM3-6B` 或 `Qwen`（可通过 `llm` 或 `transformers` 加载）
- **生成方式**：LangChain RAGChain（或自定义 retrieval + prompt）

> ✅ 优点：部署简单、轻量适合个人或小团队
>  ❌ 缺点：可扩展性一般，不适合 TB 级数据量



**方案二：llama-index + Milvus/Chroma + GGUF 模型**

- **文档处理**：llama-index 自带文档加载和分块、支持多文档管理
- **向量化模型**：支持 HuggingFace 模型或 OpenAI 接口（推荐 bge）
- **向量数据库**：Chroma（Python 内嵌，轻量）或 Milvus（适合大规模）
- **大模型**：GGUF 格式模型（用 `llama.cpp` 加载，如 `llama3`、`mistral`、`Qwen`）
- **推理引擎**：llama.cpp、llm.cpp、vLLM 等

> ✅ 优点：可插拔组件多，生态好，支持复杂场景
>  ❌ 缺点：学习曲线略高，配置略繁琐



**方案三：Haystack + Weaviate + Ollama/LMStudio（全栈解决方案）**

- **Haystack**：一个强大的 Python 框架，支持文档 QA / ChatBot / 多模态问答
- **向量库**：支持 Weaviate、Qdrant、FAISS、Milvus
- **大模型**：通过 API 接入本地 Ollama / LMStudio 中的模型（如 llama3）
- **UI 支持**：提供基本的 Web UI，可快速集成

> ✅ 优点：全家桶框架，适合企业级项目
>  ❌ 缺点：部署成本稍高，资源占用相对多



## 线上运行方案

**方案一：coze**

上传文件到知识库，直接调用即可，有手就行



**方案二：n8n**

上传文件到知识库，直接调用即可，有手就行



**方案三：transfomerjs + indexdb（web端）**

项目地址：https://github.com/Yoan98/Ncurator

通过transfomerjs来处理文本向量化：

```js
import { env, pipeline } from '@huggingface/transformers';
// Create a pipeline for feature extraction, using the full-precision model (fp32)
const pipe = await pipeline('feature-extraction', 'your-model-name', {
    dtype: "fp32",
});
const output = await pipe(inputTexts, { pooling: 'mean', normalize: true })
```

web端，要能存储大量数据的方案，也只有indexdb，部分服务端存储向量数据方案，是有专门的向量数据库的，而indexDB是类似于Mongodb的JSON存储，他这里采用的LSH方案。



## 快速部署方案

- [Langchain-Chatchat](https://github.com/chatchat-space/Langchain-Chatchat)：利用 [langchain](https://github.com/langchain-ai/langchain) 思想实现的基于本地知识库的问答应用，原理：加载文件 -> 读取文本 -> 文本分割 -> 文本向量化 -> 问句向量化 -> 在文本向量中匹配出与问句向量最相似的 `top k`个 -> 匹配出的文本作为上下文和问题一起添加到 `prompt`中 -> 提交给 `LLM`生成回答

- [fastgpt](https://fastgpt.cn/)+cow

  ![](https://cdn.jsdelivr.net/gh/pengpen1/blog-images/20250508145303109.png)

  官网docker部署链接https://doc.tryfastgpt.ai/docs/development/docker/

- [Dify](https://dify.ai/)+cow

  

## 结语

引用一下[@tempest](https://linux.do/t/topic/188797/60)的帖子当做结语

营销号啥的都别看，真想学估摸着得掏个小千报个班上。

科普看：

[Coggle 30 Days of ML（24年1/2月）：动手学RAG - 竞赛学习 - Coggle竞赛论坛](http://discussion.coggle.club/t/topic/30)
[动手学RAG：Part1 什么是RAG？_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1vt42157Si/)

看完了上面，再推荐survey，了解一下前沿： [[2312.10997\] Retrieval-Augmented Generation for Large Language Models: A Survey (arxiv.org)](https://arxiv.org/abs/2312.10997)，简单看看就行了。

RAG其实没有那么复杂的。唯一难点就是，这种前沿的东西是每天一个样子的，他会把最新研究和老的研究杂糅在一起，会很头痛，想刷最新成就只能去arxiv啃survey。

然后RAG学习路线：一开始建议跑通一个项目，然后自己搓微调模型、自己微调embedding模型，优化框架，尝试多模态模型，尝试新模块，尝试新技术，比如你说的tag了GraphRAG。排列组合需要折腾个把月。
[langchain](https://github.com/langchain-ai/langchain)，说人话就是做了几个模块。之前专精RAG的，后来把模块拆分了，models、prompts、indexs、memory、chains、agent这几个模块。
[llama_index](https://github.com/run-llama/llama_index)，类似langchain，慢慢学就了解了。



## 参考

- [个人知识库](https://www.youtube.com/watch?v=-s4RUc7fdK0)

