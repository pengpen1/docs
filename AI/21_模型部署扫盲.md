<h1 align="center" id="模型部署扫盲">模型部署扫盲</h1>

**概要：** 本章节将介绍主啵将介绍下模型部署相关的知识点。

## 一、模型结构相关知识

| 名称                                | 简要说明                                                                               |
| ----------------------------------- | -------------------------------------------------------------------------------------- |
| **Transformer**                     | LLM 的核心架构（BERT、GPT 等都是它的变种），基于多头自注意力机制，支持大规模并行计算。 |
| **Embedding**                       | 把文本、图像等离散输入转为模型可以理解的向量表示，是模型理解语义的基础。               |
| **Self-Attention**                  | 模型对输入的每个词都“看”全上下文的机制，关键在于捕捉长距离依赖。                       |
| **位置编码（Positional Encoding）** | 因为 Transformer 本身不具备顺序概念，需要手动注入“位置信息”。                          |
| **层归一化、残差连接**              | 提高深层模型稳定性和训练效率。                                                         |

## 二、训练与优化相关知识

| 名称                               | 简要说明                                                           |
| ---------------------------------- | ------------------------------------------------------------------ |
| **预训练（Pretraining）**          | 在大规模数据上训练基础能力（如语言建模）。                         |
| **微调（Fine-tuning）**            | 在特定任务/领域上再次训练模型，使其更适合该任务。                  |
| **指令微调（Instruction Tuning）** | 让模型能更好地理解用户任务意图，ChatGPT 就用了这个。               |
| **RLHF（人类反馈强化学习）**       | 通过人类反馈结果来优化模型生成的质量。                             |
| **迁移学习（Transfer Learning）**  | 利用已有模型知识在新任务上快速收敛。                               |
| **LoRA / Adapter**                 | 一种轻量级微调方法，只更新少量参数即可适配新任务，适合多场景部署。 |

## 三、部署与推理相关技术

| 名称                                 | 简要说明                                                |
| ------------------------------------ | ------------------------------------------------------- |
| **推理（Inference）**                | 使用训练好的模型进行预测或生成。                        |
| **量化（Quantization）**             | 用低精度表示权重，减少模型大小，加速推理。              |
| **蒸馏（Distillation）**             | 用大模型教小模型，让后者继承前者能力。                  |
| **剪枝（Pruning）**                  | 删除对结果影响较小的神经元或连接，进一步压缩模型。      |
| **KV 缓存（KV Cache）**              | LLM 推理时缓存前面 Token 的计算结果，极大提高生成效率。 |
| **Batching / Streaming**             | 多用户请求打包处理，或分步响应生成，提升系统效率。      |
| **并行策略（如张量并行、流水并行）** | 将模型拆分到多卡/多机，提高训练或推理速度。             |

## 四、模型格式与存储方式

| 名称                              | 简要说明                                                               |
| --------------------------------- | ---------------------------------------------------------------------- |
| **模型权重格式**                  | 如 `.pt`（PyTorch）、`.bin`、`.safetensors`、`.gguf`（用于 llama.cpp） |
| **保存结构**                      | 通常包括权重文件、模型结构定义、词表（tokenizer）等                    |
| **分片模型（sharded）**           | 将模型按文件大小拆分成多个部分，方便分布式存储与加载                   |
| **加载方式（load-in-4bit/8bit）** | 控制推理时加载哪些权重、以什么精度加载                                 |

## 五、部署环境与运行框架

| 名称              | 简要说明                                                                                                |
| ----------------- | ------------------------------------------------------------------------------------------------------- |
| **LLM 推理框架**  | 如：`Transformers`（HuggingFace）、`llama.cpp`（轻量本地部署）、`vllm`（高效多用户推理）、`ggml`、`TGI` |
| **硬件支持**      | GPU（NVIDIA）、TPU、Apple M 系列芯片、CPU 部署（量化后才可行）                                          |
| **运行方式**      | 本地部署、本地 WebUI、云服务部署、API 调用（如 OpenAI、DeepSeek 等）                                    |
| **Docker/容器化** | 可将部署过程标准化，方便快速迁移和扩展                                                                  |
| **API 接口**      | 通过 RESTful 或 WebSocket 形式接入前端、应用等                                                          |

## 六、模型应用与调优

| 名称                      | 简要说明                                                    |
| ------------------------- | ----------------------------------------------------------- |
| **Prompt Engineering**    | 设计提示词以引导模型生成正确输出，是 LLM 应用中的“编程”。   |
| **RAG（检索增强生成）**   | 结合知识库提高模型准确性与实时性（例如 ChatGPT 搜索结合）。 |
| **多轮对话管理**          | 维护上下文、处理历史记录是构建聊天机器人的关键。            |
| **安全与过滤**            | 包括敏感词过滤、有害生成检测、拒答机制等。                  |
| **用户输入预处理/后处理** | 规范输入、格式化输出，提高用户体验。                        |

## 七、评估与对比指标

| 名称                 | 简要说明                                   |
| -------------------- | ------------------------------------------ |
| **Perplexity**       | 衡量语言模型预测能力的指标（值越低越好）。 |
| **BLEU / ROUGE**     | 比较文本生成结果与参考答案的相似度。       |
| **MMLU / HellaSwag** | 通用能力评估标准题集。                     |
| **响应延迟 / TPS**   | 推理响应的效率指标（每秒生成 token 数）    |

## 总结图谱

你可以把整个 LLM 知识体系看成这样一张图：

```
           ┌───────────────┐
           │   模型结构     │
           └─────┬─────────┘
                 ↓
           ┌─────────────┐
           │  训练优化方法 │
           └─────┬───────┘
                 ↓
           ┌─────────────┐
           │  模型压缩技术 │ ←── 量化、蒸馏、剪枝、LoRA等
           └─────┬───────┘
                 ↓
           ┌──────────────┐
           │  部署与推理框架│
           └─────┬────────┘
                 ↓
           ┌──────────────┐
           │   模型应用能力 │ ←── Prompt、RAG、多轮对话
           └──────────────┘
```

### 1. **权重（Weights）**

- 模型中的“知识”其实都储存在**权重（weights）**里，它是神经网络中连接每层神经元的参数。
- 每一个权重是一个浮点数（通常是 32 位 float，即 FP32），这些数值决定了模型的行为。
- 模型中的“知识”是通过**训练过程中的数据映射关系**编码进“权重”这些数字里

**举例**：
一个 GPT 模型可能有数百亿个权重（参数），每个权重都是一个数值。模型在推理时就是通过这些数值来“决定”它的输出。

#### 如何实现数字存储知识(权重)？

#### 直觉理解：权重就像人的记忆回路

想象一个神经网络是由很多“节点”（神经元）组成的网络，每个节点之间有连接（连接的强弱由“权重”控制）。当你给一个输入时，这些连接控制着“信息流动的路径”，最终决定输出。

- 如果一个模型看到很多“狗”的图片，并学会判断“这是一只狗”；
- 那么模型会自动**调整权重数值**，让“有耳朵、有毛发、有四条腿”这种特征的组合 →“狗”的输出概率变大。

最终这些调好的“连接强度”（也就是权重）就是“知识”的体现。

#### 数学理解：函数拟合与参数优化

在数学上，神经网络本质是一个复杂的**非线性函数**：

```
scss


复制编辑
f(x; θ) → y
```

- 其中 `x` 是输入（比如一句话、图片、音频等）；
- `y` 是输出（比如分类标签、下一句文本）；
- `θ` 是参数集合，也就是我们说的“权重”；
- 学习的目标：通过训练数据，不断调整 θ，使得预测值 f(x; θ) 更接近真实 y。

训练完成后，权重 θ 被定下来了，而模型就变成了一个可以泛化的函数 —— 输入相似的东西，它能输出合理的结果。也就是说，模型**“学会了某种规律”**，而这规律是被参数 θ 所“编码”的。

#### 个例子（以文本为例）

假设我们训练一个简单的语言模型，让它学会：

```
复制编辑输入：天安门在北京，紫禁城也在__
输出：北京
```

在训练中，模型会不断尝试各种“权重组合”来让自己的预测接近“北京”这个词。

每一次预测错误，都会计算损失（loss），然后通过反向传播算法去**调整对应的权重值**。某些神经元负责捕捉“地理位置”特征，某些捕捉“地名”特征，这些能力就随着权重慢慢形成。

久而久之，权重就编码了：

- 哪些词常在一起出现；
- 哪些词有相似的上下文；
- 哪些语法结构或常识规律应该遵循。

于是我们说：**知识就被“压缩”进了这些数字里**。

#### 一个真实的例子（模型层数越深，知识越抽象）

以 BERT 为例：

- 第 1 层捕捉的是字符级模式（标点符号、大小写）；
- 中间层捕捉的是语法（动词/主谓宾）；
- 深层可以捕捉语义（谁和谁是同一个实体、是不是一句反问句）；
  这些能力都对应于不同层的“权重”分布。

---

#### 总结

| 概念     | 含义                                           |
| -------- | ---------------------------------------------- |
| 权重     | 神经元之间的“连接强度”，用数字表示             |
| 知识     | 通过训练数据中学到的规律，被编码在权重中       |
| 存储方式 | 训练中不断微调权重值，使得模型函数拟合目标行为 |

你可以把“知识”看作人类大脑对经验的归纳，而“权重”就是大脑中神经突触强度的数字化模拟。

如果对这个概念感兴趣，还可以了解：

- 信息熵与模型压缩（知识的“信息量”分布）；
- 模型解释性（如 Attention 可视化）；
- 网络层级结构如何编码不同类型知识（语法 vs 语义）。

### 2. **量化（Quantization）**

- 量化是将模型中的权重从高精度（如 FP32）转换为低精度（如 INT8、FP16）的过程。
- **目的**：减少模型大小、加快推理速度、节省内存和计算资源。
- **常见方式**：
  - FP32 → INT8（32 位变为 8 位，大小减少 75%）
  - FP32 → FP16（32 位变为 16 位，常用于 GPU）

**优点**：

- 模型文件更小；
- 运算更快（尤其是在移动设备或边缘设备上）；
- 几乎不影响模型性能（尤其是采用“感知量化”或“混合精度”时）。

### 3. **蒸馏（Distillation）**

- 蒸馏是将一个大的模型（教师模型）“压缩”为一个小模型（学生模型）的过程。
- 小模型学习大模型的“行为”，而不是完全重新训练。

**过程**：

1. 训练一个大模型（如 ChatGPT、BERT-large）；
2. 使用大模型生成大量训练样本或中间输出（如 logits）；
3. 训练一个小模型来模仿大模型的输出。

**优点**：

- 小模型计算量小，推理更快；
- 适合部署在资源受限的设备上；
- 相比直接训练，小模型继承了大模型的“知识”，表现更好。

三者关系总结：

| 名称 | 作用           | 影响               | 是否改变模型结构 |
| ---- | -------------- | ------------------ | ---------------- |
| 权重 | 模型的核心参数 | 决定模型能力       | 否               |
| 量化 | 压缩权重精度   | 加快推理、减小模型 | 否（主要改精度） |
| 蒸馏 | 训练更小模型   | 提升小模型效果     | 是（换模型结构） |

在本地部署 Qwen、LLaMA、BERT 等模型，实际流程可能是：

1. 使用量化后的模型（比如 `Qwen-7B-Chat-GGUF-q4`）以节省显存；
2. 或使用蒸馏模型（如 `TinyLLaMA` 或 `DistilBERT`）做轻量化推理；
3. 根据需求选择合适的精度（FP16、INT8）和部署方式（CPU、GPU、NPU 等）。

### 测试框架

[evalscope](https://github.com/modelscope/evalscope)

## 参考

- [huggingface](https://huggingface.co/docs/inference-providers/index)
